"""
OpenFDA
DAG auto-generated by Astro Cloud IDE.
"""

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.google.cloud.hooks.bigquery import BigQueryHook
from datetime import datetime, timedelta
import pandas as pd
import requests

# Function to generate query URL for a specific month and year
def generate_query_url(year, month):
    start_date = f"{year}{month:02d}01"
    end_date = f"{year}{month:02d}{(datetime(year, month, 1) + timedelta(days=31)).replace(day=1) - timedelta(days=1):%d}"
    query = f"https://api.fda.gov/drug/event.json?search=patient.drug.medicinalproduct:%22sildenafil+citrate%22+AND+receivedate:[{start_date}+TO+{end_date}]&count=receivedate"
    return query

# Function to fetch data from the API and save it to XCom
def fetch_openfda_data(**kwargs):
    from airflow.operators.python import get_current_context
    
    ti = kwargs['ti']
    context = get_current_context()
    execution_date = context['logical_date']
    year = execution_date.year
    month = execution_date.month

    query_url = generate_query_url(year, month)
    response = requests.get(query_url)

    if response.status_code == 200:
        data = response.json()
        df = pd.DataFrame(data['results'])
        df['time'] = pd.to_datetime(df['time'])
        # Group by week and sum the count column
        weekly_sum = df.groupby(pd.Grouper(key='time', freq='W'))['count'].sum().reset_index()
        weekly_sum["time"] = weekly_sum["time"].astype(str)
        print(weekly_sum.info())
        print(weekly_sum.head())
    else:
        weekly_sum = pd.DataFrame([])  # Return empty DataFrame if request fails

    # Push the DataFrame to XCom
    ti.xcom_push(key='openfda_data', value=weekly_sum.to_dict())

def save_to_bigquery(**kwargs):
    import pandas as pd

    ti = kwargs['ti']
    data_dict = ti.xcom_pull(task_ids='fetch_openfda_data', key='openfda_data')
    if data_dict:
        df = pd.DataFrame.from_dict(data_dict)
        hook = BigQueryHook(gcp_conn_id='google_cloud_default')  # use seu GCP_CONN_ID
        dataset_table = 'openfda.openfda_history'
        # Load dataframe to BigQuery table
        hook.insert_rows_from_dataframe(
            dataset_table=dataset_table,
            dataframe=df,
            project_id="meu-projeto-471401",
            location="US",
            write_disposition="WRITE_APPEND"
        )

# Define the DAG
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'fetch_openfda_data_monthly',
    default_args=default_args,
    description='Retrieve OpenFDA data monthly',
    schedule='@monthly',
    start_date=datetime(2020, 11, 1),
    catchup=True,
    max_active_tasks=1
)


fetch_task = PythonOperator(
    task_id='fetch_openfda_data',
    python_callable=fetch_openfda_data,
    dag=dag,
)

save_data_task = PythonOperator(
    task_id='save_to_bigquery',    
    python_callable=save_to_bigquery,
    dag=dag,
)

fetch_task >> save_data_task

